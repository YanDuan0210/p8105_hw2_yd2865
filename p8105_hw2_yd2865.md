p8105_hw2_yd2865
================
Yan Duan
2025-09-16

I’m an R Markdown document!

## Problem 1

#### Clean the data in `pols-month.csv`

``` r
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-" ) |>   # Use `separate()` to break up the variable `mon`
  mutate(
    year = as.integer(year),
    month = factor(month.name[as.integer(month)],
         levels = month.name),
         president =         # Create a `president` variable
           case_when(
             prez_gop == 1 ~ "gop",
             prez_dem == 1 ~ "dem")) |> 
  select(year, month, president, everything(), -day, -prez_gop, -prez_dem) |>  # Remove three variables
  arrange(year, month)
pols_df
```

    ## # A tibble: 822 × 9
    ##     year month     president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <int> <fct>     <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 January   dem            23      51     253      23      45     198
    ##  2  1947 February  dem            23      51     253      23      45     198
    ##  3  1947 March     dem            23      51     253      23      45     198
    ##  4  1947 April     dem            23      51     253      23      45     198
    ##  5  1947 May       dem            23      51     253      23      45     198
    ##  6  1947 June      dem            23      51     253      23      45     198
    ##  7  1947 July      dem            23      51     253      23      45     198
    ##  8  1947 August    dem            23      51     253      23      45     198
    ##  9  1947 September dem            23      51     253      23      45     198
    ## 10  1947 October   dem            23      51     253      23      45     198
    ## # ℹ 812 more rows

#### Clean the data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  separate(date, into = c("year", "month", "day"), sep = "/") |> 
  mutate(
   year = as.integer(year),
   year  = if_else(year <= 25, 2000L + year, 1900L + year),
   month = factor(month.name[as.integer(month)],
         levels = month.name)) |> 
  select(year, month, close) |> 
  arrange(year, month)
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month    close
    ##    <int> <fct>    <dbl>
    ##  1  2001 February 1995.
    ##  2  2001 February 1783.
    ##  3  2001 February 1498.
    ##  4  2001 February  826.
    ##  5  2001 February 1379.
    ##  6  2001 February 1131.
    ##  7  2001 February  856.
    ##  8  2001 February 1130.
    ##  9  2001 February 1366.
    ## 10  2001 February  980.
    ## # ℹ 777 more rows

#### Tidy the `unemployment` data

``` r
unemp_df =
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(                # Switching from “wide” to “long” format
    jan:dec,
    names_to = "month",
    values_to = "unemp_rate") |>
   mutate(         # Make sure that key variables have the same name and same values
    year = as.integer(year),
    month = match(str_to_title(month), month.abb),
    month = factor(month.name[as.integer(month)],
         levels = month.name)) |> 
  arrange(year, month)
unemp_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemp_rate
    ##    <int> <fct>          <dbl>
    ##  1  1948 January          3.4
    ##  2  1948 February         3.8
    ##  3  1948 March            4  
    ##  4  1948 April            3.9
    ##  5  1948 May              3.5
    ##  6  1948 June             3.6
    ##  7  1948 July             3.6
    ##  8  1948 August           3.9
    ##  9  1948 September        3.8
    ## 10  1948 October          3.7
    ## # ℹ 806 more rows

#### Joining datasets

``` r
# Join the datasets by merging `snp` into `pols`

pols_snp =
  left_join(pols_df, snp_df, by = c("year", "month")) 

# Merging `unemployment` into the result
merged_df = 
  left_join(pols_snp, unemp_df, by = c("year", "month")) 
merged_df
```

    ## # A tibble: 1,571 × 11
    ##     year month   president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <int> <fct>   <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 January dem            23      51     253      23      45     198    NA
    ##  2  1947 Februa… dem            23      51     253      23      45     198    NA
    ##  3  1947 March   dem            23      51     253      23      45     198    NA
    ##  4  1947 April   dem            23      51     253      23      45     198    NA
    ##  5  1947 May     dem            23      51     253      23      45     198    NA
    ##  6  1947 June    dem            23      51     253      23      45     198    NA
    ##  7  1947 July    dem            23      51     253      23      45     198    NA
    ##  8  1947 August  dem            23      51     253      23      45     198    NA
    ##  9  1947 Septem… dem            23      51     253      23      45     198    NA
    ## 10  1947 October dem            23      51     253      23      45     198    NA
    ## # ℹ 1,561 more rows
    ## # ℹ 1 more variable: unemp_rate <dbl>

This analysis utilized three datasets: `pols-month.csv`, `snp.csv` and
`unemployment.csv`.

- The `pols_df` dataset, after being organized, contains monthly data on
  the political structure of the United States starting from 1947,
  including `year`, `month`, `president` (the political party of the
  president, `gop` or `dem`), and the distribution numbers of state
  governors, senators, and representatives between the two parties (such
  as `gov_gop`, `sen_gop`, `rep_dem`).
- The `snp_df` provides the monthly closing prices of the S&P 500 index
  during the same period (use variable `close`), with `year` and `month`
  serving as the keys.
- The variable `unemp_df` represents the monthly unemployment rate in
  the United States. Originally, it was stored in columns for 12 months.
  After being organized, it was transformed into “long format” and the
  same keys of `year` and `month` were used.

During the cleaning process, the date variables in all three datasets
were unified into `year` and `month`, and the months were standardized
to the full English names of the months to ensure a smooth merge.
Eventually, we used the `left_join()` function to first merge the
`snp_df` into the `pols_df`, and then merge the `unemp_df`, resulting in
the `merged_df` data frame which contains approximately 1,571 monthly
observation records. The time span ranges from January 1947 to around
June 2015.

The final table integrates the political structure, the closing prices
of the stock market, and the unemployment rate, providing a complete
time series of data for analyzing the relationship between the political
and economic fluctuations in the United States.

## Problem 2

#### Read “Mr. Trash Wheel” table

``` r
mr_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:N")) |>
  mutate(wheel = "Mr",
         Year = as.integer(Year))               
```

#### Read “Professor Trash Wheel” table

``` r
prof_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:M")) |>
  mutate(wheel = "Professor")    
```

#### Read “Gwynns Falls Trash Wheel” table

``` r
gwyn_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynns Falls Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:L")) |>
  mutate(wheel = "Gwynnda")    
```

#### Tidy and clean data

``` r
wheel_tidy = 
  bind_rows(mr_df, prof_df, gwyn_df) |>   # Merge the three datasets
  janitor::clean_names() |> 
  rename(                      # Change the variable name
      dumpster = dumpster,
      month = month,
      year  = year,
      date  = date,
      weight = starts_with("weight"),
      volume_cubic_yards = starts_with("volume"),
      plastic_bottles = starts_with("plastic_bottles"),
      polystyrene = starts_with("polystyrene"),
      cigarette = starts_with("cigarette"),
      glass = starts_with("glass"),
      plastic = starts_with("plastic"),
      wrappers = starts_with("wrappers"),
      sports = starts_with("sports"),
      homes = starts_with("homes")) |> 
  filter(!is.na(dumpster)) |>     # Remove the rows that do not have `dumpster` data
  mutate(date = as.Date(date),
         sports = ifelse(is.na(sports), NA_integer_, as.integer(round(sports))))# Round the number of sports balls to the nearest integer and convert the result into an integer variable.
wheel_tidy
```

    ## # A tibble: 1,188 × 15
    ##    dumpster month  year date       weight volume_cubic_yards plastic1
    ##       <dbl> <chr> <dbl> <date>      <dbl>              <dbl>    <dbl>
    ##  1        1 May    2014 2014-05-16   4.31                 18     1450
    ##  2        2 May    2014 2014-05-16   2.74                 13     1120
    ##  3        3 May    2014 2014-05-16   3.45                 15     2450
    ##  4        4 May    2014 2014-05-17   3.1                  15     2380
    ##  5        5 May    2014 2014-05-17   4.06                 18      980
    ##  6        6 May    2014 2014-05-20   2.71                 13     1430
    ##  7        7 May    2014 2014-05-21   1.91                  8      910
    ##  8        8 May    2014 2014-05-28   3.7                  16     3580
    ##  9        9 June   2014 2014-06-05   2.52                 14     2400
    ## 10       10 June   2014 2014-06-11   3.76                 18     1340
    ## # ℹ 1,178 more rows
    ## # ℹ 8 more variables: polystyrene <dbl>, cigarette <dbl>, glass <dbl>,
    ## #   plastic2 <dbl>, wrappers <dbl>, sports <int>, homes <dbl>, wheel <chr>

#### The total number of observations after merging the datasets

``` r
nrow(wheel_tidy)
```

    ## [1] 1188

#### Calculate the total weight of the trash of “Professor Trash Wheel”

``` r
prof_total_weight =
  wheel_tidy |>
  drop_na(weight) |>
  filter(wheel == "Professor") |> 
  summarise(total_weight = sum(weight))
prof_total_weight
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         282.

#### Calculate the total number of cigarette butts collected by Gwynnda in June 2022

``` r
gwyn_cigs_jun22 =
  wheel_tidy |>
  drop_na(weight) |> 
  filter(wheel == "Gwynnda",
         year(date) == 2022, month(date) == 6) |>
  summarise(total_cigarette = sum(cigarette))
gwyn_cigs_jun22
```

    ## # A tibble: 1 × 1
    ##   total_cigarette
    ##             <dbl>
    ## 1           18120

This analysis utilized three datasets: “Mr. Trash Wheel”, “Professor
Trash Wheel” and “Gwynnda Falls Trash Wheel”.

- `mr_df` represents the trash collection records of “Mr. Trash Wheel”,
  including `dumpster` (trash bin number), `month`, `year`, `date`,
  `weight` (tons), `volume_cubic_yards` (cubic yards), and various
  variables representing the quantities of different types of trash
  items (such as `plastic_bottles`, `polystyrene`, `cigarette`, `glass`,
  `wrappers`, `sports`, `homes`).
- `prof_df` and `gwyn_df` contains similar records for “Professor Trash
  Wheel” and “Gwynnda Falls Trash Wheel”, with the same variable
  structure as `mr_df`.

We used the `bind_rows()` function to combine the three datasets into a
tidy data frame named `wheel_tidy`. During the cleaning process, we
standardized the variable names and data formats for the three datasets,
and rounded the value of `sports` to an integer. To distinguish the data
from different devices, we added a variable `wheel` for each
sub-dataset, with the values being `Mr`, `Professor` and `Gwynnda`
respectively.

The post-organized `wheel_tidy` dataset contains a total of 1,188
observation records and 12 variables, which comprehensively reflects the
trash collection situation of the three devices since their respective
commissioning.

## Problem 3

#### Read, tidy and clean the data in `Zip Codes.csv`

``` r
zip_df = 
  read_csv("./zillow_data/Zip Codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  mutate(
    county = str_to_title(county),
    zipcode = as.character(zip_code),
    neighborhood = as.character(na_if(neighborhood, "NA") ),
    borough = recode(county,
                     "Bronx"   = "Bronx",
                     "Kings"   = "Brooklyn",
                     "New York"= "Manhattan",
                     "Queens"  = "Queens",
                     "Richmond"= "Staten Island")) |>
  select(-zip_code) |>  
  filter(!is.na(zipcode))
zip_df
```

    ## # A tibble: 322 × 8
    ##    county state_fips county_code county_fips file_date neighborhood      zipcode
    ##    <chr>       <dbl> <chr>             <dbl> <chr>     <chr>             <chr>  
    ##  1 Bronx          36 005               36005 7/25/07   High Bridge and … 10451  
    ##  2 Bronx          36 005               36005 7/25/07   High Bridge and … 10452  
    ##  3 Bronx          36 005               36005 7/25/07   Central Bronx     10453  
    ##  4 Bronx          36 005               36005 7/25/07   Hunts Point and … 10454  
    ##  5 Bronx          36 005               36005 7/25/07   Hunts Point and … 10455  
    ##  6 Bronx          36 005               36005 7/25/07   High Bridge and … 10456  
    ##  7 Bronx          36 005               36005 7/25/07   Central Bronx     10457  
    ##  8 Bronx          36 005               36005 7/25/07   Bronx Park and F… 10458  
    ##  9 Bronx          36 005               36005 7/25/07   Hunts Point and … 10459  
    ## 10 Bronx          36 005               36005 7/25/07   Central Bronx     10460  
    ## # ℹ 312 more rows
    ## # ℹ 1 more variable: borough <chr>

#### Read, tidy and clean the Zillow data

``` r
zori_df = 
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  mutate(
    zipcode = str_pad(as.character(region_name), 5, pad = "0")) |> 
  pivot_longer(       # Arrange the date data into a single column
    cols = 10:125,              
    names_to  = "month",
    values_to = "zori") |> 
  mutate(
    month = month |>
      str_remove("^(x|X)") |> 
      str_replace_all("[_./]", "-") |>
      ymd(),
    zori  = as.numeric(zori)) |> 
  filter(month >= ymd("2015-01-01"), month <= ymd("2024-08-31")) |> 
  select(region_id, zipcode, county_name, month, zori) |> 
  arrange(zipcode, month)
zori_df
```

    ## # A tibble: 17,284 × 5
    ##    region_id zipcode county_name     month       zori
    ##        <dbl> <chr>   <chr>           <date>     <dbl>
    ##  1     61615 10001   New York County 2015-01-31 3855.
    ##  2     61615 10001   New York County 2015-02-28 3892.
    ##  3     61615 10001   New York County 2015-03-31 3898.
    ##  4     61615 10001   New York County 2015-04-30 3970.
    ##  5     61615 10001   New York County 2015-05-31 4033.
    ##  6     61615 10001   New York County 2015-06-30 4071.
    ##  7     61615 10001   New York County 2015-07-31 4067.
    ##  8     61615 10001   New York County 2015-08-31 4070.
    ##  9     61615 10001   New York County 2015-09-30 4040.
    ## 10     61615 10001   New York County 2015-10-31 4023.
    ## # ℹ 17,274 more rows

# Joining datasets

``` r
zori_tidy = 
  left_join(zip_df, zori_df, by = "zipcode") |>
  select(zipcode, borough, neighborhood, month, zori,
         county = county_name) |>
  arrange(zipcode, month, borough, neighborhood)
```

    ## Warning in left_join(zip_df, zori_df, by = "zipcode"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 1 of `x` matches multiple rows in `y`.
    ## ℹ Row 7541 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
zori_tidy
```

    ## # A tibble: 17,687 × 6
    ##    zipcode borough   neighborhood        month       zori county         
    ##    <chr>   <chr>     <chr>               <date>     <dbl> <chr>          
    ##  1 10001   Manhattan Chelsea and Clinton 2015-01-31 3855. New York County
    ##  2 10001   Manhattan Chelsea and Clinton 2015-02-28 3892. New York County
    ##  3 10001   Manhattan Chelsea and Clinton 2015-03-31 3898. New York County
    ##  4 10001   Manhattan Chelsea and Clinton 2015-04-30 3970. New York County
    ##  5 10001   Manhattan Chelsea and Clinton 2015-05-31 4033. New York County
    ##  6 10001   Manhattan Chelsea and Clinton 2015-06-30 4071. New York County
    ##  7 10001   Manhattan Chelsea and Clinton 2015-07-31 4067. New York County
    ##  8 10001   Manhattan Chelsea and Clinton 2015-08-31 4070. New York County
    ##  9 10001   Manhattan Chelsea and Clinton 2015-09-30 4040. New York County
    ## 10 10001   Manhattan Chelsea and Clinton 2015-10-31 4023. New York County
    ## # ℹ 17,677 more rows

#### Problem 3.1

``` r
summary_df =
  zori_tidy |>
  summarise(
    total_obs = n(),       # The number of observations                     
    unique_zipcode = length(unique(zipcode)),  # The number of unique ZIP codes
    unique_hood = length(unique(neighborhood[!is.na(neighborhood)])))  # The number of unique neighborhoods
summary_df
```

    ## # A tibble: 1 × 3
    ##   total_obs unique_zipcode unique_hood
    ##       <int>          <int>       <int>
    ## 1     17687            320          42

#### Problem 3.2

``` r
zip_in_zipcode =
  zip_df |>
  anti_join(unique(zori_df["zipcode"]), by = "zipcode") |>
  arrange(borough, zipcode)
zip_in_zipcode
```

    ## # A tibble: 171 × 8
    ##    county state_fips county_code county_fips file_date neighborhood      zipcode
    ##    <chr>       <dbl> <chr>             <dbl> <chr>     <chr>             <chr>  
    ##  1 Bronx          36 005               36005 7/25/07   Southeast Bronx   10464  
    ##  2 Bronx          36 005               36005 7/25/07   Hunts Point and … 10474  
    ##  3 Bronx          36 005               36005 7/25/07   Northeast Bronx   10475  
    ##  4 Bronx          36 005               36005 7/25/07   <NA>              10499  
    ##  5 Bronx          36 005               36005 7/25/07   <NA>              10550  
    ##  6 Bronx          36 005               36005 7/25/07   <NA>              10704  
    ##  7 Bronx          36 005               36005 7/25/07   <NA>              10705  
    ##  8 Bronx          36 005               36005 7/25/07   <NA>              10803  
    ##  9 Kings          36 047               36047 7/25/07   <NA>              11202  
    ## 10 Kings          36 047               36047 7/25/07   Southern Brooklyn 11224  
    ## # ℹ 161 more rows
    ## # ℹ 1 more variable: borough <chr>

The reason why the postal codes might be excluded from the Zillow
dataset is:

- Some data quality filtering: Abnormal noise or unstable sequences are
  excluded.
- Small areas at the periphery such as airports or cross-county
  boundaries may not have been collected.
- Transaction volume is too low, and Zillow does not publish it.

#### Problem 3.3

``` r
drop_top10 =
  zori_tidy |>
  filter(month == ymd("2020-01-31") | month == ymd("2021-01-31")) |>
  mutate(date_select = if_else(month == ymd("2020-01-31"), "Jan2020", "Jan2021")) |>
  select(zipcode, borough, neighborhood, date_select, zori) |>
  pivot_wider(names_from = date_select, values_from = zori) |>
  mutate(
    abs_change  = Jan2021 - Jan2020,             
    pct_change  = (Jan2021 - Jan2020) / Jan2020
  ) |>
  arrange(abs_change) |>
  slice_head(n = 10) |>
  select(zipcode, borough, neighborhood,
         price_2020_01 = Jan2020,
         price_2021_01 = Jan2021,
         abs_change, pct_change)
drop_top10
```

    ## # A tibble: 10 × 7
    ##    zipcode borough   neighborhood         price_2020_01 price_2021_01 abs_change
    ##    <chr>   <chr>     <chr>                        <dbl>         <dbl>      <dbl>
    ##  1 10007   Manhattan Lower Manhattan              6334.         5422.      -913.
    ##  2 10069   Manhattan <NA>                         4623.         3875.      -748.
    ##  3 10009   Manhattan Lower East Side              3406.         2692.      -714.
    ##  4 10016   Manhattan Gramercy Park and M…         3731.         3019.      -712.
    ##  5 10001   Manhattan Chelsea and Clinton          4108.         3398.      -710.
    ##  6 10002   Manhattan Lower East Side              3645.         2935.      -710.
    ##  7 10004   Manhattan Lower Manhattan              3150.         2444.      -706.
    ##  8 10038   Manhattan Lower Manhattan              3573.         2876.      -698.
    ##  9 10012   Manhattan Greenwich Village a…         3629.         2942.      -686.
    ## 10 10010   Manhattan Gramercy Park and M…         3697.         3012.      -685.
    ## # ℹ 1 more variable: pct_change <dbl>
