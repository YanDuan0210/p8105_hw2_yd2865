p8105_hw2_yd2865
================
Yan Duan
2025-09-16

I’m an R Markdown document!

## Problem 1

#### Clean the data in `pols-month.csv`

``` r
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-" ) |>   # Use `separate()` to break up the variable `mon`
  mutate(
    year = as.integer(year),
    month = factor(month.name[as.integer(month)],
         levels = month.name),
         president =         # Create a `president` variable
           case_when(
             prez_gop == 1 ~ "gop",
             prez_dem == 1 ~ "dem")) |> 
  select(year, month, president, everything(), -day, -prez_gop, -prez_dem) |>  # Remove three variables
  arrange(year, month)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Clean the data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  mutate(
   date  = mdy(date),
   date = if_else(date > Sys.Date(), date %m-% years(100), date)) |> 
  separate(date, into = c("year", "month", "day"), sep = "-") |>
  mutate(
   year = as.integer(year),
   month = factor(month.name[as.integer(month)],
         levels = month.name)) |> 
  select(year, month, close) |> 
  arrange(year, month)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Tidy the `unemployment` data

``` r
unemp_df =
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(                # Switching from “wide” to “long” format
    jan:dec,
    names_to = "month",
    values_to = "unemp_rate") |>
   mutate(         # Make sure that key variables have the same name and same values
    year = as.integer(year),
    month = match(str_to_title(month), month.abb),
    month = factor(month.name[as.integer(month)],
         levels = month.name)) |> 
  arrange(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Joining datasets

``` r
# Join the datasets by merging `snp` into `pols`

pols_snp =
  left_join(pols_df, snp_df, by = c("year", "month")) 

# Merging `unemployment` into the result
merged_df = 
  left_join(pols_snp, unemp_df, by = c("year", "month")) 
merged_df
```

    ## # A tibble: 822 × 11
    ##     year month   president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <int> <fct>   <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 January dem            23      51     253      23      45     198    NA
    ##  2  1947 Februa… dem            23      51     253      23      45     198    NA
    ##  3  1947 March   dem            23      51     253      23      45     198    NA
    ##  4  1947 April   dem            23      51     253      23      45     198    NA
    ##  5  1947 May     dem            23      51     253      23      45     198    NA
    ##  6  1947 June    dem            23      51     253      23      45     198    NA
    ##  7  1947 July    dem            23      51     253      23      45     198    NA
    ##  8  1947 August  dem            23      51     253      23      45     198    NA
    ##  9  1947 Septem… dem            23      51     253      23      45     198    NA
    ## 10  1947 October dem            23      51     253      23      45     198    NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemp_rate <dbl>

This analysis utilized three datasets: `pols-month.csv`, `snp.csv` and
`unemployment.csv`.

- The `pols_df` dataset has 822 rows × 9 columns , after being
  organized, contains monthly data on the political structure of the
  United States starting from 1947, including `year`, `month`,
  `president` (the political party of the president, `gop` or `dem`),
  and the distribution numbers of state governors, senators, and
  representatives between the two parties (such as `gov_gop`, `sen_gop`,
  `rep_dem`).
- The `snp_df` with 787 rows × 2 columns provides the monthly closing
  prices of the S&P 500 index during the same period (use variable
  `close`), with `year` and `month` serving as the keys.
- The variable `unemp_df` with 68 rows × 13 columns represents the
  monthly unemployment rate in the United States. Originally, it was
  stored in columns for 12 months. After being organized, it was
  transformed into “long format” and the same keys of `year` and `month`
  were used.

During the cleaning process, the date variables in all three datasets
were unified into `year` and `month`, and the months were standardized
to the full English names of the months to ensure a smooth merge.
Eventually, we used the `left_join()` function to first merge the
`snp_df` into the `pols_df`, and then merge the `unemp_df`, resulting in
the `merged_df` data frame which contains approximately 822 monthly
observation records. The time span ranges from January 1947 to around
June 2015.

The final table integrates the political structure, the closing prices
of the stock market, and the unemployment rate, providing a complete
time series of data for analyzing the relationship between the political
and economic fluctuations in the United States.

## Problem 2

#### Read “Mr. Trash Wheel” table

``` r
mr_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:N")) |>
  mutate(wheel = "Mr",
         Year = as.integer(Year))               
```

#### Read “Professor Trash Wheel” table

``` r
prof_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:M")) |>
  mutate(wheel = "Professor")    
```

#### Read “Gwynns Falls Trash Wheel” table

``` r
gwyn_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynns Falls Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:L")) |>
  mutate(wheel = "Gwynnda")    
```

#### Tidy and clean data

``` r
wheel_tidy = 
  bind_rows(mr_df, prof_df, gwyn_df) |>   # Merge the three datasets
  janitor::clean_names() |> 
  rename(                      # Change the variable name
      dumpster = dumpster,
      month = month,
      year  = year,
      date  = date,
      weight = starts_with("weight"),
      volume_cubic_yards = starts_with("volume"),
      plastic_bottles = starts_with("plastic_bottles"),
      polystyrene = starts_with("polystyrene"),
      cigarette = starts_with("cigarette"),
      glass = starts_with("glass"),
      plastic = starts_with("plastic"),
      wrappers = starts_with("wrappers"),
      sports = starts_with("sports"),
      homes = starts_with("homes")) |> 
  filter(!is.na(dumpster)) |>     # Remove the rows that do not have `dumpster` data
  mutate(date = as.Date(date),
         sports = ifelse(is.na(sports), NA_integer_, as.integer(round(sports))))# Round the number of sports balls to the nearest integer and convert the result into an integer variable.
wheel_tidy
```

    ## # A tibble: 1,188 × 15
    ##    dumpster month  year date       weight volume_cubic_yards plastic1
    ##       <dbl> <chr> <dbl> <date>      <dbl>              <dbl>    <dbl>
    ##  1        1 May    2014 2014-05-16   4.31                 18     1450
    ##  2        2 May    2014 2014-05-16   2.74                 13     1120
    ##  3        3 May    2014 2014-05-16   3.45                 15     2450
    ##  4        4 May    2014 2014-05-17   3.1                  15     2380
    ##  5        5 May    2014 2014-05-17   4.06                 18      980
    ##  6        6 May    2014 2014-05-20   2.71                 13     1430
    ##  7        7 May    2014 2014-05-21   1.91                  8      910
    ##  8        8 May    2014 2014-05-28   3.7                  16     3580
    ##  9        9 June   2014 2014-06-05   2.52                 14     2400
    ## 10       10 June   2014 2014-06-11   3.76                 18     1340
    ## # ℹ 1,178 more rows
    ## # ℹ 8 more variables: polystyrene <dbl>, cigarette <dbl>, glass <dbl>,
    ## #   plastic2 <dbl>, wrappers <dbl>, sports <int>, homes <dbl>, wheel <chr>

#### The total number of observations after merging the datasets

``` r
n_obs = nrow(wheel_tidy)
```

#### Calculate the total weight of the trash of “Professor Trash Wheel”

``` r
prof_total_weight =
  wheel_tidy |>
  drop_na(weight) |>
  filter(wheel == "Professor") |> 
  summarise(total_weight = format(round(sum(weight), 2), nsmall = 2))
```

#### Calculate the total number of cigarette butts collected by Gwynnda in June 2022

``` r
gwyn_cigs_jun22 =
  wheel_tidy |>
  drop_na(weight) |> 
  filter(wheel == "Gwynnda",
         year(date) == 2022, month(date) == 6) |>
  summarise(total_cigarette = sum(cigarette))
```

This analysis utilized three datasets: “Mr. Trash Wheel”, “Professor
Trash Wheel” and “Gwynnda Falls Trash Wheel”.

- `mr_df` represents the trash collection records of “Mr. Trash Wheel”,
  including `dumpster` (trash bin number), `month`, `year`, `date`,
  `weight` (tons), `volume_cubic_yards` (cubic yards), and various
  variables representing the quantities of different types of trash
  items (such as `plastic_bottles`, `polystyrene`, `cigarette`, `glass`,
  `wrappers`, `sports`, `homes`).
- `prof_df` and `gwyn_df` contains similar records for “Professor Trash
  Wheel” and “Gwynnda Falls Trash Wheel”, with the same variable
  structure as `mr_df`.

We used the `bind_rows()` function to combine the three datasets into a
tidy data frame named `wheel_tidy`. During the cleaning process, we
standardized the variable names and data formats for the three datasets,
and rounded the value of `sports` to an integer. To distinguish the data
from different devices, we added a variable `wheel` for each
sub-dataset, with the values being `Mr`, `Professor` and `Gwynnda`
respectively.

The post-organized `wheel_tidy` dataset contains a total of **1188**
observation records. Using the functions `filter()` and `summarise()` to
conduct conditional filtering and group summarization on the data, the
total weight of Professor’s trash collection is **282.26** tons and
Gwynnda collected **18,120** cigarette butts in June 2022, which
comprehensively reflects the trash collection situation of the three
devices since their respective commissioning.

## Problem 3

#### Read, tidy and clean the data in `Zip Codes.csv`

``` r
zip_df = 
  read_csv("./zillow_data/Zip Codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  mutate(
    zipcode = as.integer(zip_code),
    neighborhood = as.character(neighborhood),
    country = as.character(county),
    borough = recode(county,     # Recoded into the 5 borough of New York City
                     "Bronx"   = "Bronx",
                     "Kings"   = "Brooklyn",
                     "New York"= "Manhattan",
                     "Queens"  = "Queens",
                     "Richmond"= "Staten Island")) |>
  select(county, zipcode, neighborhood, borough) 
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Read, tidy and clean the Zillow data

``` r
zori_df = 
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  rename(zipcode = region_name) |> 
  mutate(
    county_name = str_replace(county_name, "county", ""),
    zipcode = as.integer(zipcode)) |>
  pivot_longer(       # Arrange the date data into a single column
    cols = 10:125,              
    names_to  = "date",
    values_to = "zori",
    names_prefix = "x") |> 
  select(region_id, zipcode, county_name, date, zori) |> 
  arrange(zipcode, date)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Joining datasets

``` r
zip_info_one =     # Remove duplicate data
  zip_df |>
  mutate(zipcode = as.integer(zipcode)) |>
  distinct(zipcode, .keep_all = TRUE)
zori_tidy = 
  zori_df |>
  left_join(zip_info_one, by = "zipcode") |>
  arrange(zipcode, date) |> 
  select(zipcode, borough, neighborhood, date, zori,
         county = county_name) |>
  arrange(zipcode, date, borough,neighborhood)
zori_tidy
```

    ## # A tibble: 17,284 × 6
    ##    zipcode borough   neighborhood        date        zori county         
    ##      <int> <chr>     <chr>               <chr>      <dbl> <chr>          
    ##  1   10001 Manhattan Chelsea and Clinton 2015_01_31 3855. New York County
    ##  2   10001 Manhattan Chelsea and Clinton 2015_02_28 3892. New York County
    ##  3   10001 Manhattan Chelsea and Clinton 2015_03_31 3898. New York County
    ##  4   10001 Manhattan Chelsea and Clinton 2015_04_30 3970. New York County
    ##  5   10001 Manhattan Chelsea and Clinton 2015_05_31 4033. New York County
    ##  6   10001 Manhattan Chelsea and Clinton 2015_06_30 4071. New York County
    ##  7   10001 Manhattan Chelsea and Clinton 2015_07_31 4067. New York County
    ##  8   10001 Manhattan Chelsea and Clinton 2015_08_31 4070. New York County
    ##  9   10001 Manhattan Chelsea and Clinton 2015_09_30 4040. New York County
    ## 10   10001 Manhattan Chelsea and Clinton 2015_10_31 4023. New York County
    ## # ℹ 17,274 more rows

#### Problem 3.1

``` r
summary_df =
  zori_tidy |>
  summarise(
    n_obs = nrow(zori_tidy),       # The number of observations                     
    unique_zipcode = length(unique(zipcode)),  # The number of unique ZIP codes
    unique_hood = length(unique(neighborhood)))  # The number of unique neighborhoods
summary_df
```

    ## # A tibble: 1 × 3
    ##   n_obs unique_zipcode unique_hood
    ##   <int>          <int>       <int>
    ## 1 17284            149          43

The “ZIP Codes” data and “Zillow” data were integrated into a neat
dataset named `zori_tidy`. The generated result shows that there are a
total of 17,284 rental observation data, covering 149 ZIP codes and
distributed across 43 neighborhoods.

#### Problem 3.2

``` r
zip_in_zipcode =
  zip_df |>
  anti_join(unique(zori_df["zipcode"]), by = "zipcode") |>
  arrange(borough, zipcode)
zip_in_zipcode
```

    ## # A tibble: 171 × 4
    ##    county zipcode neighborhood               borough 
    ##    <chr>    <int> <chr>                      <chr>   
    ##  1 Bronx    10464 Southeast Bronx            Bronx   
    ##  2 Bronx    10474 Hunts Point and Mott Haven Bronx   
    ##  3 Bronx    10475 Northeast Bronx            Bronx   
    ##  4 Bronx    10499 <NA>                       Bronx   
    ##  5 Bronx    10550 <NA>                       Bronx   
    ##  6 Bronx    10704 <NA>                       Bronx   
    ##  7 Bronx    10705 <NA>                       Bronx   
    ##  8 Bronx    10803 <NA>                       Bronx   
    ##  9 Kings    11202 <NA>                       Brooklyn
    ## 10 Kings    11224 Southern Brooklyn          Brooklyn
    ## # ℹ 161 more rows

The reason why the postal codes might be excluded from the Zillow
dataset is:

- Some data quality filtering: Abnormal noise or unstable sequences are
  excluded.
- Small areas at the periphery such as airports or cross-county
  boundaries may not have been collected.
- Transaction volume is too low, and Zillow does not publish it.

#### Problem 3.3

``` r
zori_2020 = 
  zori_tidy |>
  filter(date == "2020_01_31") |> 
  select(zipcode, borough, neighborhood, Jan2020 = zori)
zori_2021 =
  zori_tidy |>
  filter(date == "2021_01_31") |> 
  select(zipcode, borough, neighborhood, Jan2021 = zori)
zori_change = 
  zori_tidy |>
  distinct(zipcode, borough, neighborhood) |> 
  left_join(zori_2020, by = "zipcode") |> 
  left_join(zori_2021, by = "zipcode") |> 
  mutate(change = Jan2021 - Jan2020) |> 
  arrange(change)
drop_top10 = 
  zori_change |> 
  slice_head(n = 10) |> 
  select(
    zipcode, borough, neighborhood,
    price_2020_01 = Jan2020,
    price_2021_01 = Jan2021,
    change) |> 
  mutate(
    price_2020_01 = format(round(price_2020_01, 2), nsmall = 2),
    price_2021_01 = format(round(price_2021_01, 2), nsmall = 2),
    change       = format(round(change, 2), nsmall = 2))
```

``` r
knitr::kable(drop_top10,
             col.names = c("zipcode", "borough", "neighborhood",
                           "price_2020_01", "price_2021_01", "Change"))
```

| zipcode | borough | neighborhood | price_2020_01 | price_2021_01 | Change |
|---:|:---|:---|:---|:---|:---|
| 10007 | Manhattan | Lower Manhattan | 6334.21 | 5421.61 | -912.60 |
| 10069 | Manhattan | NA | 4623.04 | 3874.92 | -748.12 |
| 10009 | Manhattan | Lower East Side | 3406.44 | 2692.19 | -714.25 |
| 10016 | Manhattan | Gramercy Park and Murray Hill | 3731.14 | 3019.43 | -711.70 |
| 10001 | Manhattan | Chelsea and Clinton | 4108.10 | 3397.65 | -710.45 |
| 10002 | Manhattan | Lower East Side | 3645.42 | 2935.11 | -710.30 |
| 10004 | Manhattan | Lower Manhattan | 3149.66 | 2443.70 | -705.96 |
| 10038 | Manhattan | Lower Manhattan | 3573.20 | 2875.62 | -697.59 |
| 10012 | Manhattan | Greenwich Village and Soho | 3628.57 | 2942.34 | -686.22 |
| 10010 | Manhattan | Gramercy Park and Murray Hill | 3697.28 | 3012.35 | -684.93 |

Based on the rental data from `2020_01_31` and `2021_01_31` in the
“Zillow” dataset, identify the ZIP Code in New York City where the
rental rate decreased the most during the COVID-19 pandemic. This data
covers the five boroughs of New York and their neighborhoods, and it can
reflect the significant fluctuations in housing rents before and after
the epidemic.

According to the generated data, the top 10 ZIP Codes with the most
significant rent decreases are all located in Manhattan, with the rent
drops ranging from -684.93 to -912.60 dollars. It indicates that the
impact of the epidemic was most significant on the rents in the core
residential areas of Manhattan.
