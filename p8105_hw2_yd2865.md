p8105_hw2_yd2865
================
Yan Duan
2025-09-16

I’m an R Markdown document!

## Problem 1

#### Clean the data in `pols-month.csv`

``` r
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-" ) |>   # Use `separate()` to break up the variable `mon`
  mutate(
    year = as.integer(year),
    month = factor(month.name[as.integer(month)],
         levels = month.name),
         president =         # Create a `president` variable
           case_when(
             prez_gop == 1 ~ "gop",
             prez_dem == 1 ~ "dem")) |> 
  select(year, month, president, everything(), -day, -prez_gop, -prez_dem) |>  # Remove three variables
  arrange(year, month)
pols_df
```

    ## # A tibble: 822 × 9
    ##     year month     president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <int> <fct>     <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 January   dem            23      51     253      23      45     198
    ##  2  1947 February  dem            23      51     253      23      45     198
    ##  3  1947 March     dem            23      51     253      23      45     198
    ##  4  1947 April     dem            23      51     253      23      45     198
    ##  5  1947 May       dem            23      51     253      23      45     198
    ##  6  1947 June      dem            23      51     253      23      45     198
    ##  7  1947 July      dem            23      51     253      23      45     198
    ##  8  1947 August    dem            23      51     253      23      45     198
    ##  9  1947 September dem            23      51     253      23      45     198
    ## 10  1947 October   dem            23      51     253      23      45     198
    ## # ℹ 812 more rows

#### Clean the data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  mutate(
   date  = mdy(date),
   date = if_else(date > Sys.Date(), date %m-% years(100), date)) |> 
  separate(date, into = c("year", "month", "day"), sep = "-") |>
  mutate(
   year = as.integer(year),
   month = factor(month.name[as.integer(month)],
         levels = month.name)) |> 
  select(year, month, close) |> 
  arrange(year, month)
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month     close
    ##    <int> <fct>     <dbl>
    ##  1  1950 January    17.0
    ##  2  1950 February   17.2
    ##  3  1950 March      17.3
    ##  4  1950 April      18.0
    ##  5  1950 May        18.8
    ##  6  1950 June       17.7
    ##  7  1950 July       17.8
    ##  8  1950 August     18.4
    ##  9  1950 September  19.5
    ## 10  1950 October    19.5
    ## # ℹ 777 more rows

#### Tidy the `unemployment` data

``` r
unemp_df =
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(                # Switching from “wide” to “long” format
    jan:dec,
    names_to = "month",
    values_to = "unemp_rate") |>
   mutate(         # Make sure that key variables have the same name and same values
    year = as.integer(year),
    month = match(str_to_title(month), month.abb),
    month = factor(month.name[as.integer(month)],
         levels = month.name)) |> 
  arrange(year, month)
unemp_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemp_rate
    ##    <int> <fct>          <dbl>
    ##  1  1948 January          3.4
    ##  2  1948 February         3.8
    ##  3  1948 March            4  
    ##  4  1948 April            3.9
    ##  5  1948 May              3.5
    ##  6  1948 June             3.6
    ##  7  1948 July             3.6
    ##  8  1948 August           3.9
    ##  9  1948 September        3.8
    ## 10  1948 October          3.7
    ## # ℹ 806 more rows

#### Joining datasets

``` r
# Join the datasets by merging `snp` into `pols`

pols_snp =
  left_join(pols_df, snp_df, by = c("year", "month")) 

# Merging `unemployment` into the result
merged_df = 
  left_join(pols_snp, unemp_df, by = c("year", "month")) 
merged_df
```

    ## # A tibble: 822 × 11
    ##     year month   president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <int> <fct>   <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 January dem            23      51     253      23      45     198    NA
    ##  2  1947 Februa… dem            23      51     253      23      45     198    NA
    ##  3  1947 March   dem            23      51     253      23      45     198    NA
    ##  4  1947 April   dem            23      51     253      23      45     198    NA
    ##  5  1947 May     dem            23      51     253      23      45     198    NA
    ##  6  1947 June    dem            23      51     253      23      45     198    NA
    ##  7  1947 July    dem            23      51     253      23      45     198    NA
    ##  8  1947 August  dem            23      51     253      23      45     198    NA
    ##  9  1947 Septem… dem            23      51     253      23      45     198    NA
    ## 10  1947 October dem            23      51     253      23      45     198    NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemp_rate <dbl>

This analysis utilized three datasets: `pols-month.csv`, `snp.csv` and
`unemployment.csv`.

- The `pols_df` dataset, after being organized, contains monthly data on
  the political structure of the United States starting from 1947,
  including `year`, `month`, `president` (the political party of the
  president, `gop` or `dem`), and the distribution numbers of state
  governors, senators, and representatives between the two parties (such
  as `gov_gop`, `sen_gop`, `rep_dem`).
- The `snp_df` provides the monthly closing prices of the S&P 500 index
  during the same period (use variable `close`), with `year` and `month`
  serving as the keys.
- The variable `unemp_df` represents the monthly unemployment rate in
  the United States. Originally, it was stored in columns for 12 months.
  After being organized, it was transformed into “long format” and the
  same keys of `year` and `month` were used.

During the cleaning process, the date variables in all three datasets
were unified into `year` and `month`, and the months were standardized
to the full English names of the months to ensure a smooth merge.
Eventually, we used the `left_join()` function to first merge the
`snp_df` into the `pols_df`, and then merge the `unemp_df`, resulting in
the `merged_df` data frame which contains approximately 1,571 monthly
observation records. The time span ranges from January 1947 to around
June 2015.

The final table integrates the political structure, the closing prices
of the stock market, and the unemployment rate, providing a complete
time series of data for analyzing the relationship between the political
and economic fluctuations in the United States.

## Problem 2

#### Read “Mr. Trash Wheel” table

``` r
mr_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:N")) |>
  mutate(wheel = "Mr",
         Year = as.integer(Year))               
```

#### Read “Professor Trash Wheel” table

``` r
prof_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:M")) |>
  mutate(wheel = "Professor")    
```

#### Read “Gwynns Falls Trash Wheel” table

``` r
gwyn_df =
  read_excel(
    path  = "./Trash Wheel/202509 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynns Falls Trash Wheel",
    na    = c("NA", ".", ""),
    skip  = 1,
    range = cell_cols("A:L")) |>
  mutate(wheel = "Gwynnda")    
```

#### Tidy and clean data

``` r
wheel_tidy = 
  bind_rows(mr_df, prof_df, gwyn_df) |>   # Merge the three datasets
  janitor::clean_names() |> 
  rename(                      # Change the variable name
      dumpster = dumpster,
      month = month,
      year  = year,
      date  = date,
      weight = starts_with("weight"),
      volume_cubic_yards = starts_with("volume"),
      plastic_bottles = starts_with("plastic_bottles"),
      polystyrene = starts_with("polystyrene"),
      cigarette = starts_with("cigarette"),
      glass = starts_with("glass"),
      plastic = starts_with("plastic"),
      wrappers = starts_with("wrappers"),
      sports = starts_with("sports"),
      homes = starts_with("homes")) |> 
  filter(!is.na(dumpster)) |>     # Remove the rows that do not have `dumpster` data
  mutate(date = as.Date(date),
         sports = ifelse(is.na(sports), NA_integer_, as.integer(round(sports))))# Round the number of sports balls to the nearest integer and convert the result into an integer variable.
wheel_tidy
```

    ## # A tibble: 1,188 × 15
    ##    dumpster month  year date       weight volume_cubic_yards plastic1
    ##       <dbl> <chr> <dbl> <date>      <dbl>              <dbl>    <dbl>
    ##  1        1 May    2014 2014-05-16   4.31                 18     1450
    ##  2        2 May    2014 2014-05-16   2.74                 13     1120
    ##  3        3 May    2014 2014-05-16   3.45                 15     2450
    ##  4        4 May    2014 2014-05-17   3.1                  15     2380
    ##  5        5 May    2014 2014-05-17   4.06                 18      980
    ##  6        6 May    2014 2014-05-20   2.71                 13     1430
    ##  7        7 May    2014 2014-05-21   1.91                  8      910
    ##  8        8 May    2014 2014-05-28   3.7                  16     3580
    ##  9        9 June   2014 2014-06-05   2.52                 14     2400
    ## 10       10 June   2014 2014-06-11   3.76                 18     1340
    ## # ℹ 1,178 more rows
    ## # ℹ 8 more variables: polystyrene <dbl>, cigarette <dbl>, glass <dbl>,
    ## #   plastic2 <dbl>, wrappers <dbl>, sports <int>, homes <dbl>, wheel <chr>

#### The total number of observations after merging the datasets

``` r
nrow(wheel_tidy)
```

    ## [1] 1188

#### Calculate the total weight of the trash of “Professor Trash Wheel”

``` r
prof_total_weight =
  wheel_tidy |>
  drop_na(weight) |>
  filter(wheel == "Professor") |> 
  summarise(total_weight = sum(weight))
prof_total_weight
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         282.

#### Calculate the total number of cigarette butts collected by Gwynnda in June 2022

``` r
gwyn_cigs_jun22 =
  wheel_tidy |>
  drop_na(weight) |> 
  filter(wheel == "Gwynnda",
         year(date) == 2022, month(date) == 6) |>
  summarise(total_cigarette = sum(cigarette))
gwyn_cigs_jun22
```

    ## # A tibble: 1 × 1
    ##   total_cigarette
    ##             <dbl>
    ## 1           18120

This analysis utilized three datasets: “Mr. Trash Wheel”, “Professor
Trash Wheel” and “Gwynnda Falls Trash Wheel”.

- `mr_df` represents the trash collection records of “Mr. Trash Wheel”,
  including `dumpster` (trash bin number), `month`, `year`, `date`,
  `weight` (tons), `volume_cubic_yards` (cubic yards), and various
  variables representing the quantities of different types of trash
  items (such as `plastic_bottles`, `polystyrene`, `cigarette`, `glass`,
  `wrappers`, `sports`, `homes`).
- `prof_df` and `gwyn_df` contains similar records for “Professor Trash
  Wheel” and “Gwynnda Falls Trash Wheel”, with the same variable
  structure as `mr_df`.

We used the `bind_rows()` function to combine the three datasets into a
tidy data frame named `wheel_tidy`. During the cleaning process, we
standardized the variable names and data formats for the three datasets,
and rounded the value of `sports` to an integer. To distinguish the data
from different devices, we added a variable `wheel` for each
sub-dataset, with the values being `Mr`, `Professor` and `Gwynnda`
respectively.

The post-organized `wheel_tidy` dataset contains a total of 1,188
observation records and 12 variables. Using the functions `filter()` and
`summarise()` to conduct conditional filtering and group summarization
on the data, the total weight of Professor’s trash collection is 282.
and Gwynnda collected 18,120 cigarette butts in June 2022, which
comprehensively reflects the trash collection situation of the three
devices since their respective commissioning.

## Problem 3

#### Read, tidy and clean the data in `Zip Codes.csv`

``` r
zip_df = 
  read_csv("./zillow_data/Zip Codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  mutate(
    zipcode = as.integer(zip_code),
    neighborhood = as.character(neighborhood),
    country = as.character(county),
    borough = recode(county,     # Recoded into the 5 borough of New York City
                     "Bronx"   = "Bronx",
                     "Kings"   = "Brooklyn",
                     "New York"= "Manhattan",
                     "Queens"  = "Queens",
                     "Richmond"= "Staten Island")) |>
  select(county, zipcode, neighborhood, borough) 
zip_df
```

    ## # A tibble: 322 × 4
    ##    county zipcode neighborhood               borough
    ##    <chr>    <int> <chr>                      <chr>  
    ##  1 Bronx    10451 High Bridge and Morrisania Bronx  
    ##  2 Bronx    10452 High Bridge and Morrisania Bronx  
    ##  3 Bronx    10453 Central Bronx              Bronx  
    ##  4 Bronx    10454 Hunts Point and Mott Haven Bronx  
    ##  5 Bronx    10455 Hunts Point and Mott Haven Bronx  
    ##  6 Bronx    10456 High Bridge and Morrisania Bronx  
    ##  7 Bronx    10457 Central Bronx              Bronx  
    ##  8 Bronx    10458 Bronx Park and Fordham     Bronx  
    ##  9 Bronx    10459 Hunts Point and Mott Haven Bronx  
    ## 10 Bronx    10460 Central Bronx              Bronx  
    ## # ℹ 312 more rows

#### Read, tidy and clean the Zillow data

``` r
zori_df = 
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  rename(zipcode = region_name) |> 
  mutate(
    county_name = str_replace(county_name, "county", ""),
    zipcode = as.integer(zipcode)) |>
  pivot_longer(       # Arrange the date data into a single column
    cols = 10:125,              
    names_to  = "date",
    values_to = "zori",
    names_prefix = "x") |> 
  select(region_id, zipcode, county_name, date, zori) |> 
  arrange(zipcode, date)
zori_df
```

    ## # A tibble: 17,284 × 5
    ##    region_id zipcode county_name     date        zori
    ##        <dbl>   <int> <chr>           <chr>      <dbl>
    ##  1     61615   10001 New York County 2015_01_31 3855.
    ##  2     61615   10001 New York County 2015_02_28 3892.
    ##  3     61615   10001 New York County 2015_03_31 3898.
    ##  4     61615   10001 New York County 2015_04_30 3970.
    ##  5     61615   10001 New York County 2015_05_31 4033.
    ##  6     61615   10001 New York County 2015_06_30 4071.
    ##  7     61615   10001 New York County 2015_07_31 4067.
    ##  8     61615   10001 New York County 2015_08_31 4070.
    ##  9     61615   10001 New York County 2015_09_30 4040.
    ## 10     61615   10001 New York County 2015_10_31 4023.
    ## # ℹ 17,274 more rows

#### Joining datasets

``` r
zip_info_one =     # Remove duplicate data
  zip_df |>
  mutate(zipcode = as.integer(zipcode)) |>
  distinct(zipcode, .keep_all = TRUE)
zori_tidy = 
  zori_df |>
  left_join(zip_info_one, by = "zipcode") |>
  arrange(zipcode, date) |> 
  select(zipcode, borough, neighborhood, date, zori,
         county = county_name) |>
  arrange(zipcode, date, borough,neighborhood)
zori_tidy
```

    ## # A tibble: 17,284 × 6
    ##    zipcode borough   neighborhood        date        zori county         
    ##      <int> <chr>     <chr>               <chr>      <dbl> <chr>          
    ##  1   10001 Manhattan Chelsea and Clinton 2015_01_31 3855. New York County
    ##  2   10001 Manhattan Chelsea and Clinton 2015_02_28 3892. New York County
    ##  3   10001 Manhattan Chelsea and Clinton 2015_03_31 3898. New York County
    ##  4   10001 Manhattan Chelsea and Clinton 2015_04_30 3970. New York County
    ##  5   10001 Manhattan Chelsea and Clinton 2015_05_31 4033. New York County
    ##  6   10001 Manhattan Chelsea and Clinton 2015_06_30 4071. New York County
    ##  7   10001 Manhattan Chelsea and Clinton 2015_07_31 4067. New York County
    ##  8   10001 Manhattan Chelsea and Clinton 2015_08_31 4070. New York County
    ##  9   10001 Manhattan Chelsea and Clinton 2015_09_30 4040. New York County
    ## 10   10001 Manhattan Chelsea and Clinton 2015_10_31 4023. New York County
    ## # ℹ 17,274 more rows

#### Problem 3.1

``` r
summary_df =
  zori_tidy |>
  summarise(
    n_obs = nrow(zori_tidy),       # The number of observations                     
    unique_zipcode = length(unique(zipcode)),  # The number of unique ZIP codes
    unique_hood = length(unique(neighborhood)))  # The number of unique neighborhoods
summary_df
```

    ## # A tibble: 1 × 3
    ##   n_obs unique_zipcode unique_hood
    ##   <int>          <int>       <int>
    ## 1 17284            149          43

The “ZIP Codes” data and “Zillow” data were integrated into a neat
dataset named `zori_tidy`. The generated result shows that there are a
total of 17,284 rental observation data, covering 149 ZIP codes and
distributed across 43 neighborhoods.

#### Problem 3.2

``` r
zip_in_zipcode =
  zip_df |>
  anti_join(unique(zori_df["zipcode"]), by = "zipcode") |>
  arrange(borough, zipcode)
zip_in_zipcode
```

    ## # A tibble: 171 × 4
    ##    county zipcode neighborhood               borough 
    ##    <chr>    <int> <chr>                      <chr>   
    ##  1 Bronx    10464 Southeast Bronx            Bronx   
    ##  2 Bronx    10474 Hunts Point and Mott Haven Bronx   
    ##  3 Bronx    10475 Northeast Bronx            Bronx   
    ##  4 Bronx    10499 <NA>                       Bronx   
    ##  5 Bronx    10550 <NA>                       Bronx   
    ##  6 Bronx    10704 <NA>                       Bronx   
    ##  7 Bronx    10705 <NA>                       Bronx   
    ##  8 Bronx    10803 <NA>                       Bronx   
    ##  9 Kings    11202 <NA>                       Brooklyn
    ## 10 Kings    11224 Southern Brooklyn          Brooklyn
    ## # ℹ 161 more rows

The reason why the postal codes might be excluded from the Zillow
dataset is:

- Some data quality filtering: Abnormal noise or unstable sequences are
  excluded.
- Small areas at the periphery such as airports or cross-county
  boundaries may not have been collected.
- Transaction volume is too low, and Zillow does not publish it.

#### Problem 3.3

``` r
zori_2020 = 
  zori_tidy |>
  filter(date == "2020_01_31") |> 
  select(zipcode, borough, neighborhood, Jan2020 = zori)
zori_2021 =
  zori_tidy |>
  filter(date == "2021_01_31") |> 
  select(zipcode, borough, neighborhood, Jan2021 = zori)
zori_change = 
  zori_tidy |>
  distinct(zipcode, borough, neighborhood) |> 
  left_join(zori_2020, by = "zipcode") |> 
  left_join(zori_2021, by = "zipcode") |> 
  mutate(change = Jan2021 - Jan2020) |> 
  arrange(change)
drop_top10 = 
  zori_change |> 
  slice_head(n = 10) |> 
  select(
    zipcode, borough, neighborhood,
    price_2020_01 = Jan2020,
    price_2021_01 = Jan2021,
    change
  )
drop_top10
```

    ## # A tibble: 10 × 6
    ##    zipcode borough   neighborhood             price_2020_01 price_2021_01 change
    ##      <int> <chr>     <chr>                            <dbl>         <dbl>  <dbl>
    ##  1   10007 Manhattan Lower Manhattan                  6334.         5422.  -913.
    ##  2   10069 Manhattan <NA>                             4623.         3875.  -748.
    ##  3   10009 Manhattan Lower East Side                  3406.         2692.  -714.
    ##  4   10016 Manhattan Gramercy Park and Murra…         3731.         3019.  -712.
    ##  5   10001 Manhattan Chelsea and Clinton              4108.         3398.  -710.
    ##  6   10002 Manhattan Lower East Side                  3645.         2935.  -710.
    ##  7   10004 Manhattan Lower Manhattan                  3150.         2444.  -706.
    ##  8   10038 Manhattan Lower Manhattan                  3573.         2876.  -698.
    ##  9   10012 Manhattan Greenwich Village and S…         3629.         2942.  -686.
    ## 10   10010 Manhattan Gramercy Park and Murra…         3697.         3012.  -685.

Based on the rental data from `2020_01_31` and `2021_01_31` in the
“Zillow” dataset, identify the ZIP Code in New York City where the
rental rate decreased the most during the COVID-19 pandemic. This data
covers the five boroughs of New York and their neighborhoods, and it can
reflect the significant fluctuations in housing rents before and after
the epidemic.

According to the generated data, the top 10 ZIP Codes with the most
significant rent decreases are all located in Manhattan, with the rent
drops ranging from `-685.` to `-913.` dollars. It indicates that the
impact of the epidemic was most significant on the rents in the core
residential areas of Manhattan.
